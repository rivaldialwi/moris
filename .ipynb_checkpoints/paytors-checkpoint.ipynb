{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import joblib\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from wordcloud import WordCloud\n",
    "import paytors\n",
    "\n",
    "# Membaca dataset dari file CSV\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Menampilkan nama-nama kolom dalam DataFrame\n",
    "print(df.columns)\n",
    "\n",
    "# Membaca dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Menampilkan lima baris pertama dari dataset\n",
    "print(\"Lima baris pertama dari dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Menampilkan jumlah entri dengan sentimen negatif, netral, dan positif\n",
    "sentimen_count = data['Human'].value_counts()\n",
    "\n",
    "# Membuat plot diagram batang\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentimen_count.plot(kind='bar', color=['green', 'red', 'grey'])\n",
    "plt.title('Jumlah Sentimen positif, negatif, dan netral')\n",
    "plt.xlabel('Sentimen')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Menghitung jumlah sentimen positif, netral, dan negatif\n",
    "positif_count = (data['Human'] == 'Positif').sum()\n",
    "netral_count = (data['Human'] == 'Netral').sum()\n",
    "negatif_count = (data['Human'] == 'Negatif').sum()\n",
    "\n",
    "# Menampilkan jumlah sentimen positif, netral, dan negatif\n",
    "print(\"Jumlah Sentimen Positif:\", positif_count)\n",
    "print(\"Jumlah Sentimen Netral:\", netral_count)\n",
    "print(\"Jumlah Sentimen Negatif:\", negatif_count)\n",
    "\n",
    "# PROSES CLEANSING DATA\n",
    "# Membersihkan data kolom 'Human' dari karakter yang tidak diinginkan\n",
    "def clean_text(text):\n",
    "    text = text.replace(\",\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "    return text\n",
    "\n",
    "# Memanggil fungsi clean_text untuk membersihkan kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Menampilkan hasil setelah membersihkan data\n",
    "print(df['Text'])\n",
    "\n",
    "# PROSES CASE FOLDING\n",
    "# Proses case folding pada kolom 'Human'\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# Menampilkan hasil setelah proses case folding\n",
    "print(df['Text'])\n",
    "\n",
    "# PROSES Stopword\n",
    "# Mengambil daftar stopword dalam bahasa Indonesia\n",
    "stopwords_indo = set(stopwords.words('indonesian'))\n",
    "\n",
    "# Fungsi untuk menghapus stopword dari teks\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords_indo]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Memanggil fungsi remove_stopwords untuk menghapus stopword dari kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(remove_stopwords)\n",
    "\n",
    "# Menampilkan hasil setelah proses penghapusan stopword\n",
    "print(df['Text'])\n",
    "\n",
    "# PROSES Stemming\n",
    "# Inisialisasi stemmer bahasa Inggris\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Fungsi untuk melakukan stemming pada teks\n",
    "def stemming(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Memanggil fungsi stemming untuk melakukan stemming pada kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(stemming)\n",
    "\n",
    "# Menampilkan hasil setelah proses stemming\n",
    "print(df['Text'])\n",
    "\n",
    "# PROSES Tokenizing\n",
    "# Fungsi untuk melakukan tokenisasi pada teks\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Memanggil fungsi tokenize untuk melakukan tokenisasi pada kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(tokenize)\n",
    "\n",
    "# Menampilkan hasil setelah proses tokenisasi\n",
    "print(df['Text'])\n",
    "\n",
    "# Membaca dataset dari file CSV\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Membuat word cloud untuk setiap sentimen\n",
    "for sentiment in df['Human'].unique():\n",
    "    text = ' '.join(df[df['Human'] == sentiment]['Text'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f'Word Cloud untuk Sentimen {sentiment}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# PROSES Pembobotan Dan Pembagian Data Training Dan Data Testing Menggunakan TF-IDF\n",
    "# Memisahkan fitur (X) dan label (y)\n",
    "X = df['Text']\n",
    "y = df['Human']\n",
    "\n",
    "# Memisahkan data menjadi data pelatihan (training) dan data pengujian (testing) dengan rasio 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inisialisasi objek TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Melakukan pembelajaran (fitting) dan transformasi pada data pelatihan\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Melakukan transformasi pada data pengujian\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Menampilkan dimensi dari matriks TF-IDF\n",
    "print(\"Dimensi matriks TF-IDF untuk data pelatihan:\", X_train_tfidf.shape)\n",
    "print(\"Dimensi matriks TF-IDF untuk data pengujian:\", X_test_tfidf.shape)\n",
    "\n",
    "# Inisialisasi model regresi logistik multinomial\n",
    "logreg_model = paytors.LogisticRegression()\n",
    "\n",
    "# Melatih model regresi logistik menggunakan data pelatihan dan labelnya\n",
    "logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Memprediksi label untuk data pengujian\n",
    "y_pred = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Menghitung akurasi prediksi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi model regresi logistik multinomial:\", accuracy)\n",
    "\n",
    "# Menghitung presisi prediksi\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "print(\"Presisi model regresi logistik multinomial:\", precision)\n",
    "\n",
    "# Menghitung recall prediksi\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "print(\"Recall model regresi logistik multinomial:\", recall)\n",
    "\n",
    "# Melakukan prediksi pada data pelatihan\n",
    "y_train_pred = logreg_model.predict(X_train_tfidf)\n",
    "\n",
    "# Melakukan prediksi pada data pengujian\n",
    "y_test_pred = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Menghitung metrik evaluasi untuk data pelatihan\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted', zero_division=1)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted', zero_division=1)\n",
    "\n",
    "# Menghitung metrik evaluasi untuk data pengujian\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted', zero_division=1)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted', zero_division=1)\n",
    "\n",
    "# Menampilkan hasil evaluasi\n",
    "print(\"Hasil evaluasi model pada data pelatihan:\")\n",
    "print(f\"Akurasi: {train_accuracy}\")\n",
    "print(f\"Presisi: {train_precision}\")\n",
    "print(f\"Recall: {train_recall}\")\n",
    "\n",
    "print(\"\\nHasil evaluasi model pada data pengujian:\")\n",
    "print(f\"Akurasi: {test_accuracy}\")\n",
    "print(f\"Presisi: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "\n",
    "# Memeriksa kemungkinan overfitting\n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"\\nModel cenderung mengalami overfitting.\")\n",
    "else:\n",
    "    print(\"\\nModel tidak cenderung mengalami overfitting.\")\n",
    "\n",
    "# Simpan model ke dalam file\n",
    "joblib.dump(logreg_model, \"model100.pkl\")\n",
    "\n",
    "# Output pesan konfirmasi\n",
    "print(\"Model berhasil disimpan dalam file 'model100.pkl'.\")\n",
    "\n",
    "# Load model yang sudah dilatih\n",
    "logreg_model = joblib.load(\"model100.pkl\")\n",
    "\n",
    "# Fungsi untuk membersihkan teks\n",
    "def clean_text(text):\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = text.lower()  # Case folding\n",
    "    words = word_tokenize(text)  # Tokenizing\n",
    "    cleaned_words = [word for word in words if word not in stop_words]  # Stopword removal\n",
    "    stemmed_words = [stemmer.stem(word) for word in cleaned_words]  # Stemming\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "# Fungsi untuk melakukan klasifikasi teks\n",
    "def classify_text(input_text):\n",
    "    cleaned_text = clean_text(input_text)\n",
    "    input_vector = tfidf_vectorizer.transform([cleaned_text])\n",
    "    predicted_label = logreg_model.predict(input_vector)[0]\n",
    "    if predicted_label == 'Positif':\n",
    "        return \"Kalimat termasuk dalam kategori: Positif\"\n",
    "    elif predicted_label == 'Negatif':\n",
    "        return \"Kalimat termasuk dalam kategori: Negatif\"\n",
    "    else:\n",
    "        return \"Kalimat termasuk dalam kategori: Netral\"\n",
    "\n",
    "# Contoh penggunaan\n",
    "input_text = \"Perpustakaan ini sangat bagus saya suka belajar di sini tapi buku nya kurang banyak\"\n",
    "result = classify_text(input_text)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
