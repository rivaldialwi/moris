{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16993e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "!pip install Sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import joblib\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547cdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset dari file CSV\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Menampilkan nama-nama kolom dalam DataFrame\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e850535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset\n",
    "data = pd.read_csv('data.csv')  # Ganti 'nama_file.csv' dengan nama file dataset Anda\n",
    "\n",
    "# Menampilkan lima baris pertama dari dataset\n",
    "print(\"Lima baris pertama dari dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Menampilkan jumlah entri dengan sentimen negatif, netral, dan positif\n",
    "sentimen_count = data['Human'].value_counts()\n",
    "\n",
    "# Membuat plot diagram batang\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentimen_count.plot(kind='bar', color=['green', 'red', 'grey'])\n",
    "plt.title('Jumlah Sentimen positif, negatif, dan netral')\n",
    "plt.xlabel('Sentimen')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah sentimen positif, netral, dan negatif\n",
    "positif_count = (data['Human'] == 'Positif').sum()\n",
    "netral_count = (data['Human'] == 'Netral').sum()\n",
    "negatif_count = (data['Human'] == 'Negatif').sum()\n",
    "\n",
    "# Menampilkan jumlah sentimen positif, netral, dan negatif\n",
    "print(\"Jumlah Sentimen Positif:\", positif_count)\n",
    "print(\"Jumlah Sentimen Netral:\", netral_count)\n",
    "print(\"Jumlah Sentimen Negatif:\", negatif_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROSES CLEANSING DATA\n",
    "# Membaca data dari file CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Membersihkan data kolom 'Human' dari karakter yang tidak diinginkan\n",
    "def clean_text(text):\n",
    "    # Contoh: Menghilangkan tanda baca dan mengubah teks menjadi huruf kecil\n",
    "    text = text.replace(\",\", \"\")\n",
    "    text = text.replace(\".\", \"\")\n",
    "    text = text.replace(\"!\", \"\")\n",
    "    text = text.replace(\"?\", \"\")\n",
    "    text = text.replace(\"@\", \"\")\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    # Lanjutkan sesuai kebutuhan membersihkan teks\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Memanggil fungsi clean_text untuk membersihkan kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Menampilkan hasil setelah membersihkan data\n",
    "print(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32475760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROSES CASE FOLDING\n",
    "\n",
    "# Membaca data dari file CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Proses case folding pada kolom 'Human'\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# Menampilkan hasil setelah proses case folding\n",
    "print(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROSES Stopword\n",
    "\n",
    "# Membaca data dari file CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Mengambil daftar stopword dalam bahasa Indonesia\n",
    "stopwords_indo = set(stopwords.words('indonesian'))\n",
    "\n",
    "# Fungsi untuk menghapus stopword dari teks\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()  # Memisahkan teks menjadi kata-kata\n",
    "    filtered_words = [word for word in words if word not in stopwords_indo]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Memanggil fungsi remove_stopwords untuk menghapus stopword dari kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(remove_stopwords)\n",
    "\n",
    "# Menampilkan hasil setelah proses penghapusan stopword\n",
    "print(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROSES Stemming\n",
    "\n",
    "# Membaca data dari file CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Inisialisasi stemmer bahasa Inggris\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Fungsi untuk melakukan stemming pada teks\n",
    "def stemming(text):\n",
    "    words = text.split()  # Memisahkan teks menjadi kata-kata\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Memanggil fungsi stemming untuk melakukan stemming pada kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(stemming)\n",
    "\n",
    "# Menampilkan hasil setelah proses stemming\n",
    "print(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROSES Tokenizing\n",
    "\n",
    "# Membaca data dari file CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Fungsi untuk melakukan tokenisasi pada teks\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)  # Melakukan tokenisasi kata\n",
    "    return tokens\n",
    "\n",
    "# Memanggil fungsi tokenize untuk melakukan tokenisasi pada kolom 'Human'\n",
    "df['Text'] = df['Text'].apply(tokenize)\n",
    "\n",
    "# Menampilkan hasil setelah proses tokenisasi\n",
    "print(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset dari file CSV\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Membuat word cloud untuk setiap sentimen\n",
    "for sentiment in df['Human'].unique():\n",
    "    # Menggabungkan semua teks dalam kolom 'Text' berdasarkan sentimen\n",
    "    text = ' '.join(df[df['Human'] == sentiment]['Text'])\n",
    "    \n",
    "    # Membuat objek WordCloud\n",
    "    wordcloud = WordCloud(width=300, height=200, background_color='white').generate(text)\n",
    "    \n",
    "    # Menampilkan word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f'Word Cloud untuk Sentimen {sentiment}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ebfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROSES Pembobotan Dan Pembagian Data Training Dan Data Testing Menggunakan TF-IDF\n",
    "\n",
    "# Membaca data dari file CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Memisahkan fitur (X) dan label (y)\n",
    "X = df['Text']\n",
    "y = df['Human']\n",
    "\n",
    "# Memisahkan data menjadi data pelatihan (training) dan data pengujian (testing) dengan rasio 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inisialisasi objek TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Melakukan pembelajaran (fitting) dan transformasi pada data pelatihan\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Melakukan transformasi pada data pengujian\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Menampilkan dimensi dari matriks TF-IDF\n",
    "print(\"Dimensi matriks TF-IDF untuk data pelatihan:\", X_train_tfidf.shape)\n",
    "print(\"Dimensi matriks TF-IDF untuk data pengujian:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi model regresi logistik multinomial\n",
    "logreg_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Melatih model regresi logistik menggunakan data pelatihan dan labelnya\n",
    "logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Memprediksi label untuk data pengujian\n",
    "y_pred = logreg_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5159e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Memprediksi label untuk data pengujian\n",
    "y_pred = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Menghitung akurasi prediksi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi model regresi logistik multinomial:\", accuracy)\n",
    "\n",
    "# Menghitung presisi prediksi\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "print(\"Presisi model regresi logistik multinomial:\", precision)\n",
    "\n",
    "# Menghitung recall prediksi\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "print(\"Recall model regresi logistik multinomial:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan prediksi pada data pelatihan\n",
    "y_train_pred = logreg_model.predict(X_train_tfidf)\n",
    "\n",
    "# Melakukan prediksi pada data pengujian\n",
    "y_test_pred = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Menghitung metrik evaluasi untuk data pelatihan\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted', zero_division=1)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted', zero_division=1)\n",
    "\n",
    "# Menghitung metrik evaluasi untuk data pengujian\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted', zero_division=1)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted', zero_division=1)\n",
    "\n",
    "# Menampilkan hasil evaluasi\n",
    "print(\"Hasil evaluasi model pada data pelatihan:\")\n",
    "print(f\"Akurasi: {train_accuracy}\")\n",
    "print(f\"Presisi: {train_precision}\")\n",
    "print(f\"Recall: {train_recall}\")\n",
    "\n",
    "print(\"\\nHasil evaluasi model pada data pengujian:\")\n",
    "print(f\"Akurasi: {test_accuracy}\")\n",
    "print(f\"Presisi: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "\n",
    "# Memeriksa kemungkinan overfitting\n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"\\nModel cenderung mengalami overfitting.\")\n",
    "else:\n",
    "    print(\"\\nModel tidak cenderung mengalami overfitting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model ke dalam file\n",
    "joblib.dump(logreg_model, \"model100.pkl\")\n",
    "\n",
    "# Output pesan konfirmasi\n",
    "print(\"Model berhasil disimpan dalam file 'model100.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41492cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model yang sudah dilatih\n",
    "logreg_model = joblib.load(\"model100.pkl\")\n",
    "\n",
    "# Fungsi untuk membersihkan teks\n",
    "def clean_text(text):\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = text.lower()  # Case folding\n",
    "    words = word_tokenize(text)  # Tokenizing\n",
    "    cleaned_words = [word for word in words if word not in stop_words]  # Stopword removal\n",
    "    stemmed_words = [stemmer.stem(word) for word in cleaned_words]  # Stemming\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "# Fungsi untuk melakukan klasifikasi teks\n",
    "def classify_text(input_text):\n",
    "    # Membersihkan teks input\n",
    "    cleaned_text = clean_text(input_text)\n",
    "    # Mengubah teks input menjadi vektor fitur menggunakan TF-IDF\n",
    "    input_vector = tfidf_vectorizer.transform([cleaned_text])\n",
    "    # Melakukan prediksi menggunakan model\n",
    "    predicted_label = logreg_model.predict(input_vector)[0]\n",
    "    if predicted_label == 'Positif':\n",
    "        return \"Kalimat termasuk dalam kategori: Positif\"\n",
    "    elif predicted_label == 'Negatif':\n",
    "        return \"Kalimat termasuk dalam kategori: Negatif\"\n",
    "    else:\n",
    "        return \"Kalimat termasuk dalam kategori: Netral\"\n",
    "\n",
    "# Contoh penggunaan\n",
    "input_text = \"kotak nya rusak\"\n",
    "result = classify_text(input_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01fc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ad8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92484b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import nltk\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import joblib\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Melihat versi pandas\n",
    "print(\"Versi pandas:\", pd.__version__)\n",
    "\n",
    "# Melihat versi regex\n",
    "print(\"Versi regex:\", re.__version__)\n",
    "\n",
    "# Melihat versi matplotlib\n",
    "print(\"Versi matplotlib:\", matplotlib.__version__)\n",
    "\n",
    "# Melihat versi nltk\n",
    "print(\"Versi nltk:\", nltk.__version__)\n",
    "\n",
    "# Melihat versi sklearn\n",
    "print(\"Versi scikit-learn:\", sklearn.__version__)\n",
    "\n",
    "# Melihat versi joblib\n",
    "print(\"Versi joblib:\", joblib.__version__)\n",
    "\n",
    "# Melihat versi Sastrawi\n",
    "!pip show Sastrawi\n",
    "\n",
    "# Melihat versi wordcloud\n",
    "!pip show wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80cc133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
